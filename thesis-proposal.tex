\documentclass{article}

% \usepackage{geometry}
% \geometry{verbose,a4paper,tmargin=20mm,bmargin=25mm,lmargin=30mm,rmargin=30mm}
% \newcommand{\dataset}{{\cal D}}
% \newcommand{\fracpartial}[2]{\frac{\partial #1}{\partial  #2}}
% \setlength{\parindent}{0pt}

\usepackage[nonatbib]{neurips_2018}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}
\pagenumbering{gobble}

\begin{document}

\title{\Large Thesis proposal}
\author{Nil Adell Mill \\
        January 2020 \\ \\
        Institute of Neuroinformatics, \\
        ETH Zurich \& Zurich University}
\date{Spring 2019}

\maketitle

    \section*{Introduction \& Background}

Drug discovery---the process by which a potential new medicine is identified---is a
 complex process that encompasses the intersection of several fields (such as biology,
 statistics, chemistry or pharmacology). The entire process is a long and costly
 endeavor, with a typical time-frame of 10 to 20 years till market release and an
 estimated cost between 2 and 3 billion USD \cite{Schneider2019, Scannell2012}, with
 only 1 out of 10000 synthesized molecules obtaining market approval. Many of these
 dropouts happening at the early stages of the entire process.
 {\color{red}Subsequently}, there is a need for tools that enable us to identify better
 drug candidates.

One of the most promising directions is to improve the \emph{in-silico} methods; which
 are relatively cheap and quick, making them an interesting solution. \emph{In-silico}
 simulations then cover two main aspects: \textbf{predictive modelling}, meaning
 modeling the dynamics of the human body---such that any effect relevant to the drug or
 the disease will be captured by it---and \textbf{generative modelling}, i.e. methods to
 generate good candidates by being effective at exploring the vast space of possible
 compounds, estimated to be on the order of $10^{60}$ \cite{Reymond2012}. Several
 computational approaches have been used over the years, from molecular dynamics
 simulations to data-driven statistical methods \cite{Hung2014, Kuhn2016}. Among the
 possible approaches, deep learning (DL) has shown signs to be a potential game-changer
 in drug-discovery \cite{Dargan2019}. 
 
DL has been able to capitalize on the exponential growth of data and the higher
 availability of computational resources. DL has had remarkable success in computer
 vision (CV) \cite{Guo2016} and natural language processing (NLP) \cite{Young2018}, and
 has become the go-to solution for any problem in these two fields. For instance, in the
 case of CV, where we deal with images, a key element of any architecture's success is
 the use of convolutional layers---one will mainly observe convolutional neural networks
 (CNNs) when analyzing the state of the art in CV---which introduces a structural a
 prior based on the structure of the data \cite{Fukushima1980, LeCun1989, Ulyanov}. A
 similar approach can be proposed to we deal with biological and molecular data by
 leveraging their graph representations. Efforts in generalizing the convolution
 operator on non-euclidian structures have given rise to graph convolutional neural
 networks (GCNNs) \cite{Wu2019}. GCNNs, then, pose an opportunity to drug discovery due
 to their capacity to deal natively with graph data \cite{Sun2019}.

% {\color{red} [NOTE: I feel like there's a narrative transition missing here (from the
% previous paragraph's argument to this)]}

Nevertheless, there is a set of shared challenges for \emph{in-silico} models. One of
 them is unifying the different aspects of drug-discovery by incorporating all the
 relevant biological and chemical information when designing possible candidate
 molecules. An initial success story on that line is a recent paper
 \cite{Zhavoronkov2019} where the authors describe a deep learning method by which they
 are able to discover, synthesize, and test in an animal model, inhibitors of discoidin
 domain receptor 1 (DDR1)—a kinase implicated in fibrosis—in less than two months.

Those promising results, albeit encouraging, are just the tip of the iceberg. There is
 still a long way until a model can satisfactorily capture the biological complexity of
 an arbitrary target and produce promising candidates. On top of that, there is an added
 dimension, as such model should account for the variability from patient to patient and
 be able to generate a molecule that accommodates for all the genotypic and phenotypic
 variants, or otherwise generate different candidates for each of the populations of
 interest. That is especially important for hypercomplex diseases, such as cancer, where
 a genotypically heterogeneous tumoral population may appear within a single patient
 \cite{Boland2017}. These diverse tumor subpopulations may, in turn, react distinctly to
 a drug, leading to an evolutionary pressure that can complicate the treatment prognosis
 \cite{Enriquez-Navas2015}.

The aforementioned example illustrates the need for the development of models that can
 be conditioned based on a large set of biological factors, and meaningfully account for
 these when generating a compound or evaluating a compound's effect. In other words,
 there is a need to adopt precision medicine methods.

Finally, from a more holistic perspective, it is of interest to develop multi-scale
 models that integrate a system's complexity at all different levels. For instance, a
 model that can learn protein-compound interactions---commonly known as the docking
 problem---while at the same time use this information to predict effects of the
 introduction of the compound on the larger protein-protein interaction (PPI) network
 \cite{Sun2019}.

% {\color{red} This thesis will aim at approaching the mentioned problems.}

    \section*{Aim \& Methods}


The aim of this thesis has two distinct though interconnected objectives. One the one
 hand, analyze how the explicit use of GCNNs may open new opportunities when dealing
 with biological and chemical data. On the other hand, explore how modeling the biology
 at different scales (e.g. molecular structure v.s. molecular interaction network) may
 help create better models and, additionally, evaluate how these different scales may be
 integrated.

The project would be based on the ideas on GCNNs for drug discovery in presented
 literature\cite{Sun2019}, which will be expanded and tested in a wider framework for
 drug design proposed in a recent article \cite{Born2019}. In that context, two main
 areas of application appear. One of them is to re-design the generative model, for
 instance by reframing the variational autoencoders used for molecule generation to
 architectures that operate over graphs \cite{Simonovsky2018,Li2018, Li2018a}. The
 second area is to improve the predictive model, by finding better ways to asses the
 activity of these molecules and assess their relevance as drug candidates. In the
 specific case of the mentioned drug discovery framework, it is done by using a critic
 network \cite{Manica2019}, which can be expanded on a set of different fronts. Those
 would be: using structural data instead of SMILES\footnote{http://opensmiles.org/}
 \cite{Li, Do2019}, {\color{red} by using GCNNs on the PPI networks in a manner that
 allows for a more effective way to extract the information from them} \cite{Oskooei2019,
 Wang2019}, or by introducing particular scores (rewards) based in the interaction of
 the compound to certain targets \cite{YingkaiGao2018, Zhavoronkov2019} or the
 combination of the compound with other drugs \cite{Zitnik2018}. All these possible
 changes to the critic model would apply at different abstraction levels, that opens the
 door to integrating the representations learnt at those different levels in a single
 model \cite{Ying2018, Ma2019, Huang2019}. Furthermore, this integration could be then
 leveraged on the drug generation part of the framework.

%  This precise work will be focused on exploring all these concepts in the context of
%  designing anti-cancer drugs. 

{\color{red}The proposed ideas will be done in the context of designing anticancer
 compounds.} The work will be done in collaboration with the Computational Systems
 Biology group at IBM Research (Zurich), currently part of the iPC
 consortium\footnote{https://ipc-project.eu/}. As part of such, an end goal of this
 project is for its results to help in the consortium efforts on pediatric cancer. For
 instance in contributing to the ongoing research in neuroblastoma, the most common type
 of cancer diagnosed on the first year of life \cite{Maris2010}.

    \section*{Data \& Baselines}

The data from this project will be obtained from multiple sources including, but not
 limited to, the Genomics of Drug Sensitivity in Cancer (GDSC) databse \cite{Yang2013},
 STRING and STICH, \cite{Szklarczyk2019,Szklarczyk2016}, DrugBank \cite{Wishart2006},
 ChEMBL \cite{Gaulton2017}, PubChem \cite{Kim2019} and ZINC 15 \cite{Sterling2015}. For
 the development of the models PyTorch \cite{Paszke2019} will be used as the main
 framework, most likely alongside DeepChem\footnote{https://deepchem.io/}.

The novel predictive model will be evaluated against empirically measured properties of
 drugs in the mentioned data sources. Furthermore, the model's performance will be
 compared to that of other models in the literature. For example, by comparing IC50
 prediction values for cell-drug pairs (unseen during training) to the empirically
 measured values from the data sources, as done in \cite{Oskooei2019, Joo2019,
 Oskooei2018}. Another prospective set of benchmarks to be used are those proposed by
 MoleculeNet \cite{Wu2018}.

Previous work \cite{Theis2016} has discussed how different metrics measure different
 conceptions of performance for the evaluation of generative models. In order to deal
 with different considerations, such as diversity, novelty, molecular activity, or
 stability, metrics like the Fréchet ChemNet Distance (FCD) \cite{Preuer} have been
 proposed. In this project one of the metrics for the generative model will come from
 the predictive model, which will be used to evaluate the effectiveness of the generated
 compounds. Simultaneously, another metric for the generative model will be the
 similarity of the generated compounds to already existing drugs. An approach that has
 already been used in the literature \cite{Born2019}. Moreover, a wider benchmarking
 framework for generative models, GucaMol, was proposed recently \cite{Brown2019},
 incorporating elements like the mentioned FCD score, so it will be explored as a
 benchmark for this project.
 
 Lastly, a natural final step for the entire evaluation of the system would be the actual
 in-vitro synthesis of the generated compounds, as done in \cite{Zhavoronkov2019}.
 However, the complexity of carrying out that evaluation will likely make it far too
 ambitious for what the scope of this project is.
 
%  makes
%  it unlikely to be carried out during the execution of this project. 

% \subsection*{Practicalities}

% Work at IBM?

% \subsection*{Something else?}

% \section*{Software and Hardware Requirements}
% Outline what your specific requirements will be with regard
% to software and hardware, but note that any special requests
% might need to be approved by your supervisor and the Head of
% Department.

% Overall, you should aim to produce roughly a two-page document
% (and certainly no more than four pages)
% outlining your plan for the year.


\bibliographystyle{apalike}
\bibliography{thesis-proposal.bib}
    
\end{document}    
